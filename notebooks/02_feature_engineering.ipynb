{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "This notebook focuses on extracting and engineering features from parsed Suricata rules.\n",
    "\n",
    "We will:\n",
    "1. Extract basic features (action, protocol, ports, etc.)\n",
    "2. Extract option-based features (content, pcre, flow, etc.)\n",
    "3. Extract metadata features (classtype, priority, message)\n",
    "4. Create TF-IDF features from rule messages\n",
    "5. Combine all features into a feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from suricata_rule_clustering import parser, features\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Parsed Rules"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load the parsed rules from the previous notebook\n",
    "df = parser.load_parsed_rules('../data/parsed_rules.pkl')\n",
    "\n",
    "print(f\"Loaded {len(df)} rules\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialize feature extractor\n",
    "extractor = features.RuleFeatureExtractor()\n",
    "\n",
    "print(\"Feature extractor initialized\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Basic Features"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Extract basic features\n",
    "df_basic = extractor.extract_basic_features(df)\n",
    "\n",
    "# Show new columns\n",
    "new_cols = [col for col in df_basic.columns if col not in df.columns]\n",
    "print(f\"New feature columns: {new_cols}\")\n",
    "\n",
    "# Display sample\n",
    "df_basic[new_cols].head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract Option Features"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Extract option-based features\n",
    "df_options = extractor.extract_option_features(df_basic)\n",
    "\n",
    "# Show new columns\n",
    "new_cols = [col for col in df_options.columns if col not in df_basic.columns]\n",
    "print(f\"New option feature columns: {new_cols}\")\n",
    "\n",
    "# Display sample\n",
    "df_options[new_cols].head(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Analyze option features\n",
    "option_cols = [col for col in df_options.columns if col.startswith('has_') or col.startswith('num_')]\n",
    "\n",
    "# Show statistics for numeric option features\n",
    "print(\"Option feature statistics:\")\n",
    "df_options[option_cols].describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract Metadata Features"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Extract metadata features\n",
    "df_metadata = extractor.extract_metadata_features(df_options)\n",
    "\n",
    "# Show new columns\n",
    "new_cols = [col for col in df_metadata.columns if col not in df_options.columns]\n",
    "print(f\"New metadata feature columns: {new_cols}\")\n",
    "\n",
    "# Display sample\n",
    "if new_cols:\n",
    "    df_metadata[new_cols].head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extract Text Features (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Extract TF-IDF features from rule messages\n",
    "df_text, tfidf_matrix = extractor.extract_text_features(\n",
    "    df_metadata,\n",
    "    max_features=50,  # Start with 50 features\n",
    "    ngram_range=(1, 2)  # Unigrams and bigrams\n",
    ")\n",
    "\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"\\nTop TF-IDF features:\")\n",
    "print(extractor.tfidf_vectorizer.get_feature_names_out()[:20])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Complete Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create feature matrix for clustering\n",
    "X = extractor.create_feature_matrix(\n",
    "    df,\n",
    "    include_tfidf=True,\n",
    "    tfidf_max_features=100\n",
    ")\n",
    "\n",
    "print(f\"Final feature matrix shape: {X.shape}\")\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyze Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Check for NaN or infinite values\n",
    "print(f\"NaN values: {np.isnan(X).sum()}\")\n",
    "print(f\"Infinite values: {np.isinf(X).sum()}\")\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\nFeature matrix statistics:\")\n",
    "print(f\"Mean: {X.mean():.4f}\")\n",
    "print(f\"Std: {X.std():.4f}\")\n",
    "print(f\"Min: {X.min():.4f}\")\n",
    "print(f\"Max: {X.max():.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize feature variance\n",
    "feature_variance = X.var(axis=0)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(feature_variance)\n",
    "plt.title('Feature Variance Across All Features')\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Variance')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Features with zero variance: {(feature_variance == 0).sum()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Features"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Save the feature matrix and processed DataFrame\n",
    "np.save('../data/feature_matrix.npy', X)\n",
    "df_metadata.to_pickle('../data/processed_rules.pkl')\n",
    "\n",
    "print(\"Saved feature matrix and processed DataFrame\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We have successfully:\n",
    "- Extracted basic features (action, protocol, ports)\n",
    "- Extracted option-based features (content, pcre, flow patterns)\n",
    "- Extracted metadata features (classtype, priority, message characteristics)\n",
    "- Created TF-IDF features from rule messages\n",
    "- Combined all features into a scaled feature matrix\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Proceed to **03_clustering.ipynb** to apply clustering algorithms to the feature matrix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
